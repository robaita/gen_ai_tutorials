{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134b5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages (from rank_bm25) (2.1.2)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105cc58",
   "metadata": {},
   "source": [
    "# Sparse Retrieval (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f29209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India won the cricket match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35786/1483704122.py:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=\"India won the cricket match.\")]\n",
    "retriever = BM25Retriever.from_documents(docs)\n",
    "query = \"Who won the game?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a556510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9978ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "# Load the PDF\n",
    "loader = PyMuPDFLoader(\"data/RAMAYANA.pdf\")\n",
    "documents  = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39542923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chunk your documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32326241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Dense Retriever (FAISS + HuggingFace Embedding)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",\n",
    "                                        model_kwargs={\"device\": \"cpu\"})\n",
    "dense_vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "dense_retriever = dense_vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b200a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Sparse Retriever (BM25)\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "bm25_retriever.k = 4  # Top k documents to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa8f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create Ensemble Retriever (Combining Scores)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, bm25_retriever],\n",
    "    weights=[0.6, 0.4],  # adjust based on which signal you want stronger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705a06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Query the Hybrid Retriever\n",
    "query = \"How RAM army went to lanka?\"\n",
    "results = ensemble_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5ed1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "was ready and cheering with excitement, the Vanara army crossed \n",
      "the sea and reached Lanka. \n",
      "As soon as the Vanara army reached the gates of Lanka, Rama \n",
      "divided them into battalions and placed each group at important \n",
      "places. The whole area echoed with the sound of conches being \n",
      "...\n",
      "\n",
      "--- Result 2 ---\n",
      "37 \n",
      " \n",
      "among us who is capable of flying across the ocean. So, Please tell \n",
      "us how we can get there.” Rama also asked his trusted friend about \n",
      "Lanka’s city plan, about its main gates, about trenches built around \n",
      "the fort and many more such information to plan the attack: Though \n",
      "...\n",
      "\n",
      "--- Result 3 ---\n",
      "army? If you plan to attack Rama, you will have to defeat me first.” \n",
      "Bharatha was extremely hurt by this suspicion. But he explained to \n",
      "Guha that he would take Rama back to Ayodhya and crown him the \n",
      "king. Guha was very happy to hear this. So he helped Bharatha, his \n",
      "...\n",
      "\n",
      "--- Result 4 ---\n",
      "war with Rama, Ravana was very angry. \n",
      "Vibhishana, are you really my brother? You talk as if I am your \n",
      "enemy. I have spared you because I still have some affection for \n",
      "you. Otherwise I would have killed you this very moment. Don’t ever \n",
      "step into Lanka again. Get out from here”. \n",
      "...\n",
      "\n",
      "--- Result 5 ---\n",
      "in corners and weeping. No prayers were offered. No chanting of \n",
      "Vedas could be heard. Even one child could not found playing in the \n",
      "park. There was a deathly silence everywhere. The worried Bharatha \n",
      "first went to his father’s chambers but found empty. So he went to \n",
      "...\n",
      "\n",
      "--- Result 6 ---\n",
      "Bharatha is coming here with a big army to kill you. His mother \n",
      "banished you to the forest. He will not hesitate to kill him” he said \n",
      "angrily. \n",
      "...\n",
      "\n",
      "--- Result 7 ---\n",
      "Ayodhya.” \n",
      "Bharatha was stunned to hear this, Enraged, he told his mother, and \n",
      "“I am ashamed to call you as my mother. You are nothing but evil. \n",
      "How could you banish Rama to the forest?  \n",
      "Hadn’t you loved him more than you loved me? Alas! You have killed \n",
      "...\n",
      "\n",
      "--- Result 8 ---\n",
      "army and his retinue to cross the Ganga. \n",
      "As Bharatha and his army approached Chitrakut, Lakshmana saw \n",
      "them coming. He recognized the flag fluttering atop Bharatha chariot \n",
      "and at once informed Rama about this “Brother, take up your bow, \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# 7. Display results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content[:300], \"\\n...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
