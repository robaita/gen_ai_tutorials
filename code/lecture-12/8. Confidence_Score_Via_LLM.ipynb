{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7762d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6338ec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRI RAMA JAYAM \n",
      "RAMAYANA FOR CHILDREN \n",
      "Compiled by\n",
      "{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2013-04-14T19:39:50-07:00', 'source': 'data/RAMAYANA.pdf', 'file_path': 'data/RAMAYANA.pdf', 'total_pages': 45, 'format': 'PDF 1.5', 'title': 'RAMAYANA FOR CHILDREN', 'author': 'Sony', 'subject': 'Compiled by', 'keywords': '', 'moddate': '2013-04-14T19:39:50-07:00', 'trapped': '', 'modDate': \"D:20130414193950-07'00'\", 'creationDate': \"D:20130414193950-07'00'\", 'page': 0}\n",
      "1 \n",
      " \n",
      "Contents \n",
      " \n",
      "1 RAMAYANA FOR CHILDREN .........\n",
      "{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2013-04-14T19:39:50-07:00', 'source': 'data/RAMAYANA.pdf', 'file_path': 'data/RAMAYANA.pdf', 'total_pages': 45, 'format': 'PDF 1.5', 'title': 'RAMAYANA FOR CHILDREN', 'author': 'Sony', 'subject': 'Compiled by', 'keywords': '', 'moddate': '2013-04-14T19:39:50-07:00', 'trapped': '', 'modDate': \"D:20130414193950-07'00'\", 'creationDate': \"D:20130414193950-07'00'\", 'page': 1}\n",
      "2 \n",
      " \n",
      "1 RAMAYANA FOR CHILDREN \n",
      " \n",
      "1.1 THE BIRTH OF R\n",
      "{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2013-04-14T19:39:50-07:00', 'source': 'data/RAMAYANA.pdf', 'file_path': 'data/RAMAYANA.pdf', 'total_pages': 45, 'format': 'PDF 1.5', 'title': 'RAMAYANA FOR CHILDREN', 'author': 'Sony', 'subject': 'Compiled by', 'keywords': '', 'moddate': '2013-04-14T19:39:50-07:00', 'trapped': '', 'modDate': \"D:20130414193950-07'00'\", 'creationDate': \"D:20130414193950-07'00'\", 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "# Load the PDF\n",
    "loader = PyMuPDFLoader(\"data/RAMAYANA.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Each doc now contains `page_content` and `metadata`\n",
    "for doc in docs[0:3]:\n",
    "    print(doc.page_content[:50])  # Preview text\n",
    "    print(doc.metadata)            # {'source': 'data/ramayana.pdf', 'page': 0}\n",
    "\n",
    "# Example: define chapters by page ranges (you can adjust this)\n",
    "chapter_map = {\n",
    "    \"THE BIRTH OF RAMA\": range(2, 4),\n",
    "    \"The Valiant Princes\": range(4, 7),\n",
    "    \"SITA'S SWAYAMVAR\": range(6, 9),\n",
    "    \"KAIKEYI AND HER WISHES\": range(8, 22),\n",
    "    \"The demons in the forests\": range(21, 25),\n",
    "    \"The Kidnapping of Sita\": range(24, 27),\n",
    "    \"Rama searches for Sita\": range(28, 30),\n",
    "    \"The land of the monkeys\": range(29, 34),\n",
    "    \"Hanuman meets Sita - Lanka is destroyed\": range(34, 38),\n",
    "    \"The War\": range(37, 44),  # Extend to end of document or actual page if known\n",
    "}\n",
    "\n",
    "# Assign chapter metadata\n",
    "tagged_documents = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # print(f\"Processing page {i + 1} of {doc.page_content[0:50]}\")\n",
    "    for chapter, pages in chapter_map.items():\n",
    "        pages = list(pages)\n",
    "        # print(\"Pages:\",pages)\n",
    "        if i in pages:\n",
    "            chapter_name = chapter\n",
    "            break\n",
    "        else:\n",
    "            chapter_name = \"Unknown Chapter\"\n",
    "    \n",
    "    # print(f\"Chapter: {chapter_name} for page {i + 1}\")\n",
    "    new_doc = Document(page_content=doc.page_content, metadata={\"chapter\": chapter_name, **doc.metadata})\n",
    "    tagged_documents.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c97868f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs created: 45\n",
      "First paragraph: 3 \n",
      " \n",
      "1.2 The Valiant Princes \n",
      " \n",
      "The four princes g\n",
      "Metadata of first paragraph: {'chapter': 'THE BIRTH OF RAMA', 'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2013-04-14T19:39:50-07:00', 'source': 'data/RAMAYANA.pdf', 'file_path': 'data/RAMAYANA.pdf', 'total_pages': 45, 'format': 'PDF 1.5', 'title': 'RAMAYANA FOR CHILDREN', 'author': 'Sony', 'subject': 'Compiled by', 'keywords': '', 'moddate': '2013-04-14T19:39:50-07:00', 'trapped': '', 'modDate': \"D:20130414193950-07'00'\", 'creationDate': \"D:20130414193950-07'00'\", 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "# Paragraph-level splitting with metadata retention\n",
    "def split_into_paragraphs(text, metadata):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    return [\n",
    "        Document(page_content=p.strip(), metadata=metadata)\n",
    "        for p in paragraphs if p.strip()\n",
    "    ]\n",
    "\n",
    "# Rebuild the documents list with correct metadata\n",
    "documents = []\n",
    "for doc in tagged_documents:\n",
    "    paragraphs = split_into_paragraphs(doc.page_content, doc.metadata)\n",
    "    documents.extend(paragraphs)\n",
    "\n",
    "# ✅ Preview result\n",
    "print(f\"Total paragraphs created: {len(documents)}\")\n",
    "print(f\"First paragraph: {documents[3].page_content[:50]}\")\n",
    "print(f\"Metadata of first paragraph: {documents[3].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e385ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedder and vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",\n",
    "                                        model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7487e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Prompt Template\n",
    "template = \"\"\"\n",
    "You are a Ramayana expert.\n",
    "\n",
    "Use the below context to answer the user's question.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ RetrievalQA Chain with confidence scoring\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # ✅ The language model used to generate answers (e.g., OpenAI, Claude, etc.)\n",
    "    chain_type=\"stuff\",  # ✅ Defines how documents are passed to the LLM.\n",
    "                         # \"stuff\" = concatenates all retrieved docs into a single string prompt.\n",
    "                         # Alternatives include \"map_reduce\", \"refine\", etc.\n",
    "    retriever=retriever,  # ✅ The retriever object (e.g., FAISS, Chroma) that fetches relevant documents from the vector store.\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": qa_prompt  # ✅ Custom prompt template used to guide the LLM's answer generation.\n",
    "                             # You define how the context and question should be formatted for the LLM.\n",
    "    },\n",
    "    return_source_documents=True  # ✅ When True, returns not only the answer but also the source documents used to generate it.\n",
    "                                  # Useful for auditing, debugging, or citation.\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ad0bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Confidence Scoring Prompt\n",
    "confidence_template = \"\"\"\n",
    "Given the context and answer below, rate how well the answer is supported by the context on a scale of 0 to 1.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Score (only return a number between 0 and 1):\n",
    "\"\"\"\n",
    "confidence_prompt = PromptTemplate.from_template(confidence_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14a6c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Confidence scoring function\n",
    "def get_confidence_score(context, answer):\n",
    "    scoring_prompt = confidence_prompt.format(context=context, answer=answer)\n",
    "    response = llm(scoring_prompt)\n",
    "    try:\n",
    "        return float(response.strip())\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "# ✅ Run the whole pipeline\n",
    "def query_with_confidence(question):\n",
    "    result = qa_chain(question)\n",
    "    context_metadata = [doc.metadata['chapter'] for doc in result['source_documents']]\n",
    "    # print(\"Context Metadata:\", context_metadata)\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in result['source_documents']])\n",
    "    answer = result[\"result\"]\n",
    "    confidence = get_confidence_score(context_text, answer)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"confidence_score\": confidence,\n",
    "        \"source_docs\": context_metadata\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54c82054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Dasahratha\n",
      "Confidence Score: 0.9\n",
      "Sources: ['KAIKEYI AND HER WISHES']\n"
     ]
    }
   ],
   "source": [
    "# ✅ Example Query\n",
    "response = query_with_confidence(\"Who was Rama's father?\")\n",
    "print(\"Answer:\", response[\"answer\"])\n",
    "print(\"Confidence Score:\", response[\"confidence_score\"])\n",
    "print(\"Sources:\", list(set(response[\"source_docs\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
