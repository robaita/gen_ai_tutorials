{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d908441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyMuPDFLoader(\"data/RAMAYANA.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a384c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",\n",
    "                                        model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21cf6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "1.3 SITA'S SWAYAMVAR \n",
      " \n",
      "Vishwamitra, Rama and Laks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "1.3 SITA'S SWAYAMVAR .............................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "to look exactly like Sita. He then took this fake \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "extremely beautiful Sita made an ideal couple. \n",
      " \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "response. So, she made a fervent plea to the trees\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "Rama and Lakshmana at once knew that Sita was in d\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "This city was ruled by Janaka, loved and respected\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "been built around the city and it is difficult to \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the story behind Sita's swayamvar?\"\n",
    "top_k = 8\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=top_k)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content[0:50]}\\n\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b484acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain.schema import Document\n",
    "from typing import List, Tuple\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "def get_scoring_prompt(doc: Document, query: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for the LLM to score the relevance of a document to a query.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "            You are a helpful assistant. A user asked a question:\n",
    "            \"{query}\"\n",
    "\n",
    "            Below is a candidate context:\n",
    "            \\\"\\\"\\\"{doc.page_content}\\\"\\\"\\\"\n",
    "\n",
    "            Rate how well this context answers the question on a scale of 1 to 10, where 10 means very relevant and 1 means not relevant.\n",
    "            Just return the number.\n",
    "            \"\"\"\n",
    "\n",
    "def score_documents_with_llm(query: str, docs: List[Document]) -> List[Tuple[Document, int]]:\n",
    "    \"\"\"\n",
    "    Score and rerank documents for a query using an LLM.\n",
    "    Returns a list of (Document, score) tuples, sorted by score descending.\n",
    "    \"\"\"\n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        prompt = get_scoring_prompt(doc, query)\n",
    "        score_str = llm.invoke(prompt)\n",
    "        # print(f\"Score: {score_str}, Type: {type(score_str)}\")\n",
    "        try:\n",
    "            score_value = score_str.content\n",
    "            # print(f\"Score value: {score_value}\")\n",
    "            score = int(score_value)\n",
    "        except Exception:\n",
    "            score = 0\n",
    "        scored_docs.append((doc, score))\n",
    "    return sorted(scored_docs, key=itemgetter(1), reverse=True)\n",
    "\n",
    "# Usage:\n",
    "reranked_docs = score_documents_with_llm(query, retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95782f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 (Score: 1):\n",
      "1.3 SITA'S SWAYAMVAR .............................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 2 (Score: 1):\n",
      "to look exactly like Sita. He then took this fake \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 3 (Score: 1):\n",
      "extremely beautiful Sita made an ideal couple. \n",
      " \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 4 (Score: 1):\n",
      "response. So, she made a fervent plea to the trees\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 5 (Score: 1):\n",
      "Rama and Lakshmana at once knew that Sita was in d\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 6 (Score: 1):\n",
      "been built around the city and it is difficult to \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 7 (Score: 0):\n",
      "1.3 SITA'S SWAYAMVAR \n",
      " \n",
      "Vishwamitra, Rama and Laks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Document 8 (Score: 0):\n",
      "This city was ruled by Janaka, loved and respected\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (doc, score) in enumerate(reranked_docs):\n",
    "    print(f\"Document {i+1} (Score: {score}):\\n{doc.page_content[0:50]}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca1d3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Answer:\n",
      " The document does not provide information on the story behind Sita's swayamvar.\n",
      "SOURCES: data/RAMAYANA.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "# Select top reranked docs\n",
    "top_docs = [doc for doc, score in reranked_docs[:3]]\n",
    "\n",
    "# QA generation\n",
    "qa_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
    "response = qa_chain({\"input_documents\": top_docs, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "print(\"ðŸ“– Answer:\\n\", response[\"output_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
