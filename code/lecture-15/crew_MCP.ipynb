{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b25679c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c12837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/pydantic/fields.py:1089: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'items', 'anyOf', 'enum', 'properties'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warn(\n",
      "\u001b[92m01:33:11 - LiteLLM:INFO\u001b[0m: utils.py:2991 - \n",
      "LiteLLM completion() model= gpt-4; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è MCP Tools: ['search_sita_references']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2991</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>; provider = openai                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=722153;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850333;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\u001b\\\u001b[2m2991\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-\u001b[1;36m4\u001b[0m; provider = openai                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=699917;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=701670;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:15 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=165178;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=375928;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\u001b\\\u001b[2m1213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4-0613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=300584;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=535681;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=42162;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=880421;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=958098;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=845978;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:15 - LiteLLM:INFO\u001b[0m: utils.py:2991 - \n",
      "LiteLLM completion() model= gpt-4; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2991</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>; provider = openai                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=930062;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721119;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\u001b\\\u001b[2m2991\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-\u001b[1;36m4\u001b[0m; provider = openai                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:26] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=714941;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898679;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:26 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=839400;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=437831;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\u001b\\\u001b[2m1213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:26 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4-0613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=753347;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=175924;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=378731;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494594;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=32226;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=502647;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:27 - LiteLLM:INFO\u001b[0m: utils.py:2991 - \n",
      "LiteLLM completion() model= gpt-4; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2991</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>; provider = openai                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=164572;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41404;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\u001b\\\u001b[2m2991\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-\u001b[1;36m4\u001b[0m; provider = openai                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=225816;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=588266;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:31 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=475421;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=7118;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\u001b\\\u001b[2m1213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4-0613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=369114;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=516377;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=918052;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=132184;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=918065;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=774567;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:31 - LiteLLM:INFO\u001b[0m: utils.py:2991 - \n",
      "LiteLLM completion() model= gpt-4; provider = openai\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2991</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>; provider = openai                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=648969;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=917332;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#2991\u001b\\\u001b[2m2991\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-\u001b[1;36m4\u001b[0m; provider = openai                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/18/25 01:33:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/18/25 01:33:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=849349;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=838329;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:40 - LiteLLM:INFO\u001b[0m: utils.py:1213 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=621529;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=994414;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/utils.py#1213\u001b\\\u001b[2m1213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:33:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4-0613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=766203;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=795162;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=537529;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655700;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> selected model name for cost calculation: openai/gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0613</span>     <a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cost_calculator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m selected model name for cost calculation: openai/gpt-\u001b[1;36m4\u001b[0m-\u001b[1;36m0613\u001b[0m     \u001b]8;id=419587;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py\u001b\\\u001b[2mcost_calculator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=519852;file:///home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/litellm/cost_calculator.py#655\u001b\\\u001b[2m655\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final Output from Summarizer Agent:\n",
      "\n",
      "In the Ramayana, Sita's journey unfolds across several books. In Bala Kanda, we learn about her birth and marriage to Rama. Ayodhya Kanda sees Sita deciding to accompany Rama into exile from Ayodhya. In Aranya Kanda, she is abducted by the demon king Ravana. Sundara Kanda then narrates how Hanuman, the monkey god, finds Sita in Ashoka Vatika in Lanka. Sita's rescue by Rama, followed by her Agni Pariksha (trial by fire), is the focus of Yuddha Kanda. Finally, Uttara Kanda narrates the story of Sita's second exile and her final departure to Mother Earth.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai_tools import MCPServerAdapter\n",
    "from mcp import StdioServerParameters\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "api_key = open(\"data/key.txt\").read().strip()\n",
    "\n",
    "def main():\n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python3\",\n",
    "        args=[\"mcp_server.py\"],\n",
    "        env={**os.environ}\n",
    "    )\n",
    "\n",
    "    with MCPServerAdapter(server_params) as mcp_tools:\n",
    "        print(\"üõ†Ô∏è MCP Tools:\", [t.name for t in mcp_tools])\n",
    "\n",
    "        llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, openai_api_key=api_key)\n",
    "\n",
    "        # Define agents\n",
    "        researcher = Agent(\n",
    "            role=\"Research Analyst\",\n",
    "            goal=\"Find references to Sita in Ramayana\",\n",
    "            backstory=\"Expert in mythology, skilled in extracting key facts\",\n",
    "            tools=mcp_tools,\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "        summarizer = Agent(\n",
    "            role=\"Content Summarizer\",\n",
    "            goal=\"Summarize information clearly for educational use\",\n",
    "            backstory=\"Writes clear and concise summaries for students\",\n",
    "            tools=mcp_tools,\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "        # Define tasks\n",
    "        task1 = Task(\n",
    "            description=\"Use MCP tool to research all references to Sita across the Ramayana.\",\n",
    "            expected_output=\"A detailed list of instances with chapter references.\",\n",
    "            agent=researcher\n",
    "        )\n",
    "\n",
    "        task2 = Task(\n",
    "            description=\"Summarize the references to Sita in under 300 words.\",\n",
    "            expected_output=\"A well-structured educational summary.\",\n",
    "            agent=summarizer\n",
    "        )\n",
    "\n",
    "        crew = Crew(agents=[researcher, summarizer], tasks=[task1, task2], verbose=False)\n",
    "        result = crew.kickoff()\n",
    "\n",
    "        print(\"\\n‚úÖ Final Output from Summarizer Agent:\\n\")\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
