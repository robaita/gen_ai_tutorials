{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa213c2",
   "metadata": {},
   "source": [
    "# Ask Questions from Ramayan using LangGraph\n",
    "In this project, we aim to build an intelligent agent that can read the ancient Indian epic \"Ramayana - Childerens book\", understand its content, and answer user questions based on it. To do this, we use a powerful Retrieval-Augmented Generation (RAG) pipeline â€” where the AI first retrieves relevant parts of the document, then generates an answer using a Large Language Model (LLM).\n",
    "\n",
    "To manage the control flow and modular structure of the system, we use LangGraph â€” a library that enables building stateful, multi-step AI workflows using a graph-based abstraction.\n",
    "\n",
    "## Step-1: Data Ingestion\n",
    "âœ… Task:\n",
    "1. Load the Ramayan.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1df63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph\n",
    "# !pip install --upgrade langchain langchain-core langchain-openai\n",
    "# !pip install graphviz\n",
    "# !pip install 'langgraph[visualization]'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab7fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/langchain_community/embeddings/sentence_transformer.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.schema import Document\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd649e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF\n",
    "loader = PyMuPDFLoader(\"data/RAMAYANA.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Example: define chapters by page ranges (you can adjust this)\n",
    "chapter_map = {\n",
    "    \"Introduction\".upper(): range(0, 2),\n",
    "    \"THE BIRTH OF RAMA\".upper(): range(2, 3),\n",
    "    \"The Valiant Princes\".upper(): range(3, 6),\n",
    "    \"SITA'S SWAYAMVAR\".upper(): range(6, 8),\n",
    "    \"KAIKEYI AND HER WISHES\".upper(): range(7, 21),\n",
    "    \"The demons in the forests\".upper(): range(21, 24),\n",
    "    \"The Kidnapping of Sita\".upper(): range(24, 27),\n",
    "    \"Rama searches for Sita\".upper(): range(27, 29),\n",
    "    \"The land of the monkeys\".upper(): range(29, 33),\n",
    "    \"Hanuman meets Sita - Lanka is destroyed\".upper(): range(33, 37),\n",
    "    \"The War\".upper(): range(37, 46),  \n",
    "}\n",
    "\n",
    "# Assign chapter metadata\n",
    "tagged_documents = []\n",
    "for i, doc in enumerate(documents):\n",
    "    # print(f\"Processing page {i + 1} of {doc.page_content[0:50]}\")\n",
    "    for chapter, pages in chapter_map.items():\n",
    "        pages = list(pages)\n",
    "        # print(\"Pages:\",pages)\n",
    "        if i in pages:\n",
    "            chapter_name = chapter\n",
    "            break\n",
    "        else:\n",
    "            chapter_name = \"Unknown Chapter\"\n",
    "    \n",
    "    # print(f\"Chapter: {chapter_name} for page {i + 1}\")\n",
    "    new_doc = Document(page_content=doc.page_content, metadata={\"chapter\": chapter_name, **doc.metadata})\n",
    "    tagged_documents.append(new_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c32931",
   "metadata": {},
   "source": [
    "## Step-2: Data Chunking (Paragraph Chunking)\n",
    "âœ… Task:\n",
    "2. Chunk the text into manageable segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf22c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paragraph-level splitting\n",
    "def split_into_paragraphs(text):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    return [Document(page_content=p.strip()) for p in paragraphs if p.strip()]\n",
    "\n",
    "documents = []\n",
    "for doc in tagged_documents:\n",
    "    paragraphs = split_into_paragraphs(doc.page_content)\n",
    "    documents.extend(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc1caa",
   "metadata": {},
   "source": [
    "## Step-3: Data Storage\n",
    "âœ… Task:\n",
    "1. Generate embeddings from the chunks\n",
    "2. Store in a vector database (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a3739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56844/2313260310.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",\n",
      "/home/avinash/Desktop/dr_avinash/generative_ai/lecture-8/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedder and vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",\n",
    "                                        model_kwargs={\"device\": \"cpu\"})\n",
    "vectorstore = FAISS.from_documents(documents, embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10342e6",
   "metadata": {},
   "source": [
    "## Step 4- Define LangGraph Nodes\n",
    "âœ… Task:\n",
    "Create LangGraph nodes:\n",
    "1. retriever_node to fetch relevant chunks\n",
    "2. llm_node to answer based on those chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c70df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "ou are a gentle storyteller who explains things in a simple, step-by-step way that even a child can understand.\n",
    "Whenever someone asks a question, you tell the answer as a short story around 100 words, using clear and easy words. Base your story only on the information provided in the context. When you refer to something from the book, kindly show the page number in square brackets like this: [Page 10].\n",
    "\n",
    "### Context Chunks:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "input_variables=[\"context\", \"question\"],\n",
    "template=PROMPT_TEMPLATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Shared state type\n",
    "from typing import List, TypedDict, Optional\n",
    "\n",
    "# Load OpenAI API key from a file\n",
    "file = open('data/key.txt', 'r')\n",
    "# Read the API key from the file\n",
    "api_key = file.read().strip()\n",
    "# Close the file\n",
    "file.close()\n",
    "# ðŸ§  Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.2)  # Remove openai_api_key=api_key\n",
    "\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    question: str # field for the question\n",
    "    context_docs: List[str] # field for context documents\n",
    "    answer: str # field for the answer\n",
    "    chat_history: List[str]  # field for memory\n",
    "    critique_llm: Optional[str]  # Field for post-analysis\n",
    "\n",
    "\n",
    "# Retrieval node\n",
    "def retrieve_node(state: RAGState) -> RAGState:\n",
    "    query_vector = embedding_model.embed_query(state['question'])\n",
    "    docs = vectorstore.similarity_search_by_vector(query_vector, k=3)\n",
    "    return {**state, \"context_docs\": [doc.page_content for doc in docs]}\n",
    "\n",
    "# LLM node\n",
    "def generate_answer_node(state: RAGState) -> RAGState:\n",
    "    context = \"\\n\\n\".join(state[\"context_docs\"])\n",
    "    chat_history = \"\\n\".join(state.get(\"chat_history\", []))\n",
    "    prompt = (\n",
    "        f\"You are a helpful assistant answering questions based on the Ramayana.\\n\\n\"\n",
    "        f\"Previous conversation:\\n{chat_history}\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Current Question: {state['question']}\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "    answer = llm.invoke(prompt)\n",
    "    updated_chat = state[\"chat_history\"] + [f\"Q: {state['question']}\", f\"A: {answer.content}\"]\n",
    "    return {**state, \"answer\": answer.content, \"chat_history\": updated_chat}\n",
    "\n",
    "# Critique node\n",
    "def critique_node(state: RAGState) -> RAGState:\n",
    "    prompt = (\n",
    "        f\"As a critique assistant, rate the clarity and relevance of the following answer.\\n\"\n",
    "        f\"Question: {state['question']}\\n\"\n",
    "        f\"Answer: {state['answer']}\\n\"\n",
    "        f\"Rate from 1 (poor) to 5 (excellent) with a short justification:\"\n",
    "    )\n",
    "    critique_response = llm.invoke(prompt)\n",
    "    return {**state, \"critique_llm\": critique_response.content}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedb7f8",
   "metadata": {},
   "source": [
    "## Step-5: Build LangGraph DAG\n",
    "âœ… Task:\n",
    "1. Connect the nodes using StateGraph\n",
    "2. Set input/output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9772eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"generate\", generate_answer_node)\n",
    "graph.add_node(\"critique\", critique_node)\n",
    "\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"critique\")\n",
    "graph.set_finish_point(\"critique\")\n",
    "\n",
    "rag_chain = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26489fd",
   "metadata": {},
   "source": [
    "## Step 6: Ask Questions with LangGraph Agent\n",
    "âœ… Task:\n",
    "1. Provide user questions\n",
    "2. Return LangGraph-generated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc1f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! Ask questions about the Ramayana (type 'exit' to stop).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Kaikeyi sent Ram to the forest because of two boons granted to her by King Dasharatha in the past. She asked for these boons to be fulfilled at the instigation of her maid Manthara. The first boon was to make her son Bharatha the king of Ayodhya, and the second was to send Ram, the eldest son and the original heir to the throne, to the forest for 14 years. This was done to ensure that Bharatha's rule was unchallenged.\n",
      "Critique: 5\n",
      "\n",
      "The answer is very clear and directly addresses the question. It provides the reasons why Kaikeyi sent Ram to the forest, giving enough context and detail to fully explain the situation. The relevance is high as it directly answers the question and stays on topic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start with an empty memory\n",
    "chat_state = {\n",
    "    \"chat_history\": [],\n",
    "}\n",
    "\n",
    "print(\"Welcome! Ask questions about the Ramayana (type 'exit' to stop).\\n\")\n",
    "\n",
    "while True:\n",
    "    user_question = input(\"You: \")\n",
    "    if user_question.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    # Build state for this turn\n",
    "    input_state = {\n",
    "        \"question\": user_question,\n",
    "        \"chat_history\": chat_state[\"chat_history\"],\n",
    "        \"context_docs\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"critique_llm\": \"\",\n",
    "    }\n",
    "\n",
    "    # Run the graph\n",
    "    result = rag_chain.invoke(input_state)\n",
    "\n",
    "    # Update memory\n",
    "    chat_state[\"chat_history\"] = result[\"chat_history\"]\n",
    "\n",
    "    # Print response\n",
    "    print(f\"Assistant: {result['answer']}\")\n",
    "    print(f\"Critique: {result['critique_llm']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876489e9",
   "metadata": {},
   "source": [
    "# Visualize LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0690e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "graph_image_data = rag_chain.get_graph().draw_mermaid_png()\n",
    "display(Image(graph_image_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
