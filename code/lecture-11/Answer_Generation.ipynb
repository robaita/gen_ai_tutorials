{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1a439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b8f5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "database_name = \"chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab46b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read key from file (or load from env manually)\n",
    "with open(\"data/key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "# Create embeddings for the chunks\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f304d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded existing vector store.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if os.path.exists(database_name) and os.listdir(database_name):\n",
    "    # Load existing vector store\n",
    "    vectorstore = Chroma(persist_directory=database_name, embedding_function=embedding_model)\n",
    "    print(\"‚úÖ Loaded existing vector store.\")\n",
    "else:\n",
    "    print(\"‚ùå No existing vector store found. Please run the indexing script first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd670f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "2 \n",
      " \n",
      "1 RAMAYANA FOR CHILDREN \n",
      " \n",
      "1.1 THE BIRTH OF RAMA \n",
      " \n",
      "Ayodhya was a magnificent city on the banks of the river Sarayu in \n",
      "Kosala Country .It had wide roads, huge buildings, beautiful parks \n",
      "and glittering shops. The people of the city lived a happy and \n",
      "contented life as they were ruled by a wonderful king called \n",
      "Dasharatha. He cared for his people very deeply. \n",
      " \n",
      "King Dasahratha had three wives, Kaushalya, Sumitra and Kaikeyi....\n",
      "\n",
      "--- Result 2 ---\n",
      "44 \n",
      " \n",
      "Vashishta blessed Rama and with their consent, Rama agreed to \n",
      "become the king. \n",
      "Soon Rama was crowned the king of Ayodhya. The coronation was \n",
      "conducted on a grand scale, Rama and Sita were seated on the \n",
      "throne, Lakshmana, Bharatha and Shatrugna stood behind them \n",
      "Hanuman sat at Rama‚Äôs feet. \n",
      "People rejoiced about this happy event. The festivities continued for \n",
      "a week and Rama made generous gifts to everyone.  \n",
      "Sri Rama ruled over Ayodhya for many years. People lived a happy,...\n",
      "\n",
      "--- Result 3 ---\n",
      "contented life in the kingdom and this glorious reign was hailed as \n",
      "Rama Rajya. \n",
      " \n",
      "This is the story of Ramayana .This epic was written by Maharishi \n",
      "Valmiki. Reading Ramayana will help us to follow Rama‚Äôs ideals, his \n",
      "devotion towards his parents, his values and his truthfulness. Let us \n",
      "all strive to be better human beings....\n"
     ]
    }
   ],
   "source": [
    "query = \"Who was Lord Rama?\"\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\\n{doc.page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2852b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant answering questions based on the provided context.\n",
    "\n",
    "### Context Chunks:\n",
    "{context}\n",
    "\n",
    "### Task:\n",
    "Using the context above, answer the user's question **precisely** and **cite the page numbers** you used in square brackets like this: [Page 2], [Page 44].\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3be1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(chunks):\n",
    "    formatted = \"\"\n",
    "    for doc in chunks:\n",
    "        page = doc.metadata.get(\"page\", \"N/A\")\n",
    "        summary = doc.page_content.strip().split(\"\\n\")[0][:300]\n",
    "        formatted += f\"[Page {page}]: {summary}...\\n\"\n",
    "    return formatted\n",
    "\n",
    "\n",
    "context_block = format_context(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4be5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Prompt ---\n",
      " \n",
      "You are a helpful assistant answering questions based on the provided context.\n",
      "\n",
      "### Context Chunks:\n",
      "[Page 2]: 2 ...\n",
      "[Page 44]: 44 ...\n",
      "[Page 44]: contented life in the kingdom and this glorious reign was hailed as ...\n",
      "\n",
      "\n",
      "### Task:\n",
      "Using the context above, answer the user's question **precisely** and **cite the page numbers** you used in square brackets like this: [Page 2], [Page 44].\n",
      "\n",
      "### Question:\n",
      "Who was Lord Rama?\n",
      "\n",
      "### Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=PROMPT_TEMPLATE\n",
    ")\n",
    "final_prompt = prompt.format(context=context_block, question=query)\n",
    "print(\"\\n--- Final Prompt ---\\n\", final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8177310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "response = llm(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "## Identity\n",
    "You are an intelligent and friendly AI Appointment Assistant for [COMPANY NAME]. Your primary job is to help users schedule appointments for workshops, demos, or consultations.\n",
    "\n",
    "## Scope\n",
    "- Assist in collecting key appointment information:\n",
    "  - Full Name\n",
    "  - Preferred Date and Time for a quick call\n",
    "  - Email ID\n",
    "  - Phone Number\n",
    "  - Workshop or service details\n",
    "- Provide basic guidance about the scheduling process.\n",
    "- Escalate special requests or unavailable slots to a human agent.\n",
    "\n",
    "## Responsibility\n",
    "- Always start with a warm greeting.\n",
    "- Ask clarifying questions step by step to gather required information.\n",
    "- Offer time slots (if available) or acknowledge user preferences.\n",
    "- Confirm appointment details before finalizing.\n",
    "- Close with a courteous summary and ask if further help is needed.\n",
    "\n",
    "## Chain of Thought (for complex queries)\n",
    "- Break down user intent.\n",
    "- Ask for missing information in a logical sequence.\n",
    "- If user asks for multiple appointments or group bookings, handle each one by confirming details.\n",
    "- If availability is limited, suggest alternative times.\n",
    "\n",
    "## Response Style\n",
    "- Friendly and professional tone.\n",
    "- Short and clear responses.\n",
    "- Bullet or numbered format if multiple steps are explained.\n",
    "- Use polite confirmations: \"Got it\", \"Thanks\", \"Perfect\".\n",
    "\n",
    "## Guardrails\n",
    "- **Privacy**: Do not ask for unnecessary personal information.\n",
    "- **Accuracy**: Only share available slots and service details from the official source.\n",
    "- **Escalation**: If the user has a special case or booking problem, escalate to a human support agent.\n",
    "\n",
    "## Instructions\n",
    "- **Greeting**: Always open with a friendly welcome.\n",
    "  _Example_: \"Hi there! üëã I‚Äôm here to help you book your appointment. Let‚Äôs get started!\"\n",
    "  \n",
    "- **Information Gathering**: Ask for:\n",
    "  1. Full Name  \n",
    "  2. Preferred Date & Time for a quick call  \n",
    "  3. Email ID  \n",
    "  4. Phone Number  \n",
    "  5. Workshop or service details  \n",
    "\n",
    "- **Complex Query Handling**: If a user has multiple queries, handle them sequentially. If unsure, escalate politely.\n",
    "\n",
    "- **Closing**: End the chat with a confirmation.\n",
    "  _Example_: \"Thanks, your appointment is confirmed for [DATE & TIME]. We‚Äôll contact you at [EMAIL/PHONE]. Is there anything else I can assist you with today?\"\n",
    "\n",
    "---\n",
    "\n",
    "üì• **User Query**:\n",
    "{customer_query}\n",
    "\n",
    "ü§ñ **Your Response**:\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
