{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO9A1xPkeEBG9Vepxw9mlgH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tUgTE6RqUphV","executionInfo":{"status":"ok","timestamp":1747369390626,"user_tz":-330,"elapsed":7,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}},"outputId":"74a3a1e2-8ec7-45f5-f86f-0bbf8b24195a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n"]}],"source":["# Step 1: Install and import necessary libraries\n","import nltk\n","nltk.download('gutenberg')\n","from nltk.corpus import gutenberg\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","import numpy as np\n","\n","\n","\n"]},{"cell_type":"code","source":["# Step 2: Load text data\n","raw_text = gutenberg.raw('carroll-alice.txt')\n","raw_text = raw_text.lower().replace('\\n', ' ')\n","\n","print(raw_text[0:500])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyXAfxcJVFr9","executionInfo":{"status":"ok","timestamp":1747369475324,"user_tz":-330,"elapsed":16,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}},"outputId":"4b136c8e-41cd-4722-fea4-63b3e10e0764"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[alice's adventures in wonderland by lewis carroll 1865]  chapter i. down the rabbit-hole  alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pictures or conversation?'  so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy an\n"]}]},{"cell_type":"code","source":["# Step 3: Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([raw_text])\n","total_words = len(tokenizer.word_index) + 1\n","\n"],"metadata":{"id":"56AHOWNLVLMf","executionInfo":{"status":"ok","timestamp":1747369390696,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Step 4: Create input sequences\n","token_list = tokenizer.texts_to_sequences([raw_text])[0]\n","input_sequences = []\n","sequence_length = 5\n","\n","for i in range(sequence_length, len(token_list)):\n","    input_sequences.append(token_list[i-sequence_length:i+1])\n","\n","input_sequences = np.array(input_sequences)\n","X = input_sequences[:, :-1]\n","y = input_sequences[:, -1]\n","y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n","\n","\n"],"metadata":{"id":"F3jx5VC3VMay","executionInfo":{"status":"ok","timestamp":1747369390805,"user_tz":-330,"elapsed":110,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Step 5: Build LSTM model\n","model = Sequential([\n","    Embedding(total_words, 64, input_length=sequence_length),\n","    LSTM(128),\n","    Dense(total_words, activation='softmax')\n","])\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, y, epochs=20, batch_size=256)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDbwogbeVOKl","executionInfo":{"status":"ok","timestamp":1747369463333,"user_tz":-330,"elapsed":24216,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}},"outputId":"fa3c3cba-8e68-4306-a740-88e0b37f05f9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0503 - loss: 7.2933\n","Epoch 2/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0589 - loss: 6.1029\n","Epoch 3/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0586 - loss: 5.9789\n","Epoch 4/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0720 - loss: 5.8659\n","Epoch 5/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0834 - loss: 5.7734\n","Epoch 6/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0924 - loss: 5.6308\n","Epoch 7/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0967 - loss: 5.5186\n","Epoch 8/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1067 - loss: 5.3941\n","Epoch 9/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1122 - loss: 5.3159\n","Epoch 10/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1194 - loss: 5.2077\n","Epoch 11/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1250 - loss: 5.1342\n","Epoch 12/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1338 - loss: 5.0205\n","Epoch 13/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1430 - loss: 4.9424\n","Epoch 14/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1557 - loss: 4.8108\n","Epoch 15/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1617 - loss: 4.7422\n","Epoch 16/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1658 - loss: 4.6472\n","Epoch 17/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1678 - loss: 4.5821\n","Epoch 18/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1808 - loss: 4.4777\n","Epoch 19/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1835 - loss: 4.4181\n","Epoch 20/20\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1874 - loss: 4.3322\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c67f19afe50>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Step 6: Prediction function\n","def predict_next_word(seed_text, next_words=1):\n","    for _ in range(next_words):\n","        token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_seq = pad_sequences([token_seq], maxlen=sequence_length, padding='pre')\n","        predicted = np.argmax(model.predict(token_seq, verbose=0), axis=-1)[0]\n","        seed_text += \" \" + tokenizer.index_word[predicted]\n","    return seed_text\n","\n","# Example use\n","print(predict_next_word(\"alice was beginning\", next_words=5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pgEd-rwVF3g","executionInfo":{"status":"ok","timestamp":1747369519492,"user_tz":-330,"elapsed":330,"user":{"displayName":"Dr. Avinash Kumar Singh","userId":"03688237427667000371"}},"outputId":"e3b93584-25e4-4e8b-b03d-57e0d0ae6b46"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["alice was beginning to be a little voice\n"]}]}]}