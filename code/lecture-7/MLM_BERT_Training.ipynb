{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81caa4a5bd8b49d7bea7b67a7dc5ce88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b65e11b02cdd48e2b254a5dd2505b181",
              "IPY_MODEL_7cdbb3bebfa44fab8b5d62acde159a43",
              "IPY_MODEL_d1995ae8e43c4979a61106bb1bb207d7"
            ],
            "layout": "IPY_MODEL_ace88d53f3f84a16b64a3cc734cd901c"
          }
        },
        "b65e11b02cdd48e2b254a5dd2505b181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c151b15c92e4589a6022a0b17a15bc3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab013a85af33410b857d1bff43ee7861",
            "value": "Map:‚Äá100%"
          }
        },
        "7cdbb3bebfa44fab8b5d62acde159a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ab71f0e47940a78a927d98f0141b21",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fb76c7ceba24be28c6337e3264eba87",
            "value": 5000
          }
        },
        "d1995ae8e43c4979a61106bb1bb207d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f450bef32e441faae8ca50eee6c0ad",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cea0e28a743748919de9db2e921e68f0",
            "value": "‚Äá5000/5000‚Äá[00:01&lt;00:00,‚Äá5128.88‚Äáexamples/s]"
          }
        },
        "ace88d53f3f84a16b64a3cc734cd901c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c151b15c92e4589a6022a0b17a15bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab013a85af33410b857d1bff43ee7861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95ab71f0e47940a78a927d98f0141b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb76c7ceba24be28c6337e3264eba87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54f450bef32e441faae8ca50eee6c0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea0e28a743748919de9db2e921e68f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Masked Language Model Training with BERT\n",
        "\n",
        "This notebook demonstrates how to train a Masked Language Model (MLM) using BERT. The key steps include:\n",
        "- üìä Dataset preparation\n",
        "- üßæ Tokenization and masking\n",
        "- ‚öôÔ∏è Configuration of training parameters\n",
        "- üèãÔ∏è Training the model\n",
        "- üîç Inference using masked token prediction\n"
      ],
      "metadata": {
        "id": "Qgltz20yqKiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "PDgQbWLxsAWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 1: Dataset Preparation\n",
        "We'll use a publicly available text dataset. You can replace this with your own custom data.\n"
      ],
      "metadata": {
        "id": "NLTyU-KcqPh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"train.csv\", header=None, names=[\"Class Index\", \"Title\", \"Description\"])\n",
        "df[\"text\"] = df[\"Title\"] + \" \" + df[\"Description\"]\n",
        "texts = df[\"text\"].tolist()\n",
        "\n",
        "texts= texts [0:5000] # taking only 2000 samples\n",
        "# Display sample\n",
        "print(\"Sample Text:\\n\", texts[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0bkN9e1qK0o",
        "outputId": "91a42683-3d04-4906-9e6e-1bc60f5c6bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text:\n",
            " Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßæ Step 2: Tokenization and Masking\n",
        "We‚Äôll use the BERT tokenizer and apply random masking (MLM-style) using Hugging Face's built-in `DataCollatorForLanguageModeling`.\n"
      ],
      "metadata": {
        "id": "MkBhMx0jqYU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": texts})\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "81caa4a5bd8b49d7bea7b67a7dc5ce88",
            "b65e11b02cdd48e2b254a5dd2505b181",
            "7cdbb3bebfa44fab8b5d62acde159a43",
            "d1995ae8e43c4979a61106bb1bb207d7",
            "ace88d53f3f84a16b64a3cc734cd901c",
            "0c151b15c92e4589a6022a0b17a15bc3",
            "ab013a85af33410b857d1bff43ee7861",
            "95ab71f0e47940a78a927d98f0141b21",
            "2fb76c7ceba24be28c6337e3264eba87",
            "54f450bef32e441faae8ca50eee6c0ad",
            "cea0e28a743748919de9db2e921e68f0"
          ]
        },
        "id": "1PlJojGKqcaS",
        "outputId": "ecc9f32c-bc61-4339-f1f6-a83d0afd869a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81caa4a5bd8b49d7bea7b67a7dc5ce88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15  # 15% of tokens will be replaced with [MASK]\n",
        ")"
      ],
      "metadata": {
        "id": "sbHppWGQrPTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñ®Ô∏è Example: Masked Training Samples\n",
        "Let‚Äôs visualize how the `DataCollatorForLanguageModeling` randomly masks tokens in the input sequences.\n"
      ],
      "metadata": {
        "id": "EGdfIk1OrlED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# Select a few tokenized samples\n",
        "sample_batch = tokenized_dataset.select(range(3))\n",
        "\n",
        "# Convert the Dataset slice to a list of dictionaries\n",
        "# This extracts each sample as a dictionary\n",
        "samples_list = [sample_batch[i] for i in range(len(sample_batch))]\n",
        "\n",
        "# Apply masking by passing the list of dictionaries to the data_collator\n",
        "masked = data_collator(samples_list)\n",
        "\n",
        "# Get the token IDs for CLS and PAD\n",
        "cls_token_id = tokenizer.cls_token_id\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Decode original and masked inputs\n",
        "print(\"üìÑ Original vs. Masked Samples:\\n\")\n",
        "for i in range(3):\n",
        "    # Access input_ids directly from the masked batch output\n",
        "    input_ids = masked[\"input_ids\"][i]\n",
        "    # Original ids can be accessed from the selected dataset\n",
        "    original_ids = sample_batch[\"input_ids\"][i]\n",
        "\n",
        "    print(f\"Example {i+1}:\")\n",
        "    # Decode original (which are lists of integers)\n",
        "    print(\"Original:\", tokenizer.decode(original_ids, skip_special_tokens=True))\n",
        "\n",
        "    # Decode masked output without skipping special tokens first\n",
        "    masked_decoded = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
        "\n",
        "    # Manually replace [CLS] and [PAD] with spaces or empty strings\n",
        "    # Using replace might lead to issues if [CLS] or [PAD] is part of a word.\n",
        "    # A more robust approach involves iterating through token IDs and decoding selectively,\n",
        "    # but for a quick visualization, string replacement can work if you are careful.\n",
        "    # Let's replace with spaces for better readability of remaining tokens.\n",
        "    cleaned_masked_decoded = masked_decoded.replace(tokenizer.cls_token, \"\").replace(tokenizer.pad_token, \"\")\n",
        "\n",
        "    print(\"Masked  :\", cleaned_masked_decoded.strip()) # strip to remove leading/trailing spaces from replacement\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uPSTDsrrnub",
        "outputId": "3b2be8f7-8432-41fb-9c08-721744fb8c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Original vs. Masked Samples:\n",
            "\n",
            "Example 1:\n",
            "Original: wall st. bears claw back into the black ( reuters ) reuters - short - sellers, wall street ' s dwindling \\ band of ultra - cynics, are seeing green again.\n",
            "Masked  : wall st. [MASK] claw back into the black ( reuters ) reuters - short [MASK] [MASK], wall street ' s dwindling \\ band of ultra - cynics, are seeing green [MASK]. [SEP]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "Original: carlyle looks toward commercial aerospace ( reuters ) reuters - private investment firm carlyle group, \\ which has a reputation for making well - timed and occasionally \\ controversial plays in the defense industry, has quietly placed \\ its bets on another part of the market.\n",
            "Masked  : [MASK]le [MASK] toward commercial aerospace ( reuters ) [MASK] - private investment firm carlyle group, [MASK] which [MASK] a reputation [MASK] makingiol - timed [MASK] occasionally \\ controversial plays in the defense industry, has quietly placed \\ its bets on another part [MASK] the market. [SEP]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "Original: oil and economy cloud stocks ' outlook ( reuters ) reuters - soaring crude prices plus worries \\ about the economy and the outlook for earnings are expected to \\ hang over the stock market next week during the depth of the \\ summer doldrums.\n",
            "Masked  : oil and economy cloud stocks ' outlook ( reuters ) reuters [MASK] soaring sarcastic prices plus worries \\ about the [MASK] [MASK] the outlook for earnings [MASK] expected to \\ hang over the stock market next week during the depth of [MASK] eats summer doldrums. [SEP]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Step 3: Model and Training Configuration\n",
        "We'll fine-tune `bert-base-uncased` using the prepared dataset and collator.\n"
      ],
      "metadata": {
        "id": "MoGvrFf1qgG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-mlm\",\n",
        "    # evaluation_strategy=\"no\", # Removed this argument as it caused a TypeError\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCdj5ZwFqg0H",
        "outputId": "856476ef-e569-4693-cb93-d3889a90faa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèãÔ∏è Step 4: Train the Model\n",
        "Let‚Äôs now train our BERT model with the dataset we‚Äôve prepared.\n"
      ],
      "metadata": {
        "id": "5bSi09rfqm7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "8jF2IJhcqngr",
        "outputId": "7dd10028-6e6d-41e6-9059-ba6c715ced42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-d748906289dd>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 03:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.967100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.502600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.448700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.462700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=625, training_loss=2.5865390258789063, metrics={'train_runtime': 183.4579, 'train_samples_per_second': 27.254, 'train_steps_per_second': 3.407, 'total_flos': 164503008000000.0, 'train_loss': 2.5865390258789063, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Step 5: Inference ‚Äî Predicting Masked Tokens\n",
        "Now let‚Äôs use the trained BERT model to fill in `[MASK]` in a sentence.\n"
      ],
      "metadata": {
        "id": "e2_1wbOKqpNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Example: Predict the masked word\n",
        "sentence = \"The [MASK] sat on the mat.\"\n",
        "results = fill_mask(sentence)\n",
        "\n",
        "print(\"Predictions for [MASK]:\")\n",
        "for r in results:\n",
        "    print(f\"{r['token_str']:>10s} | score: {r['score']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N6awT_Vqrgo",
        "outputId": "71bb6bc0-de67-4ab6-fae3-21e41c570ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for [MASK]:\n",
            "       man | score: 0.0851\n",
            "      girl | score: 0.0399\n",
            "       boy | score: 0.0367\n",
            "       dog | score: 0.0341\n",
            "     woman | score: 0.0209\n"
          ]
        }
      ]
    }
  ]
}