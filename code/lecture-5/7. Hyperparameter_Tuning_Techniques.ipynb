{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51c434c",
   "metadata": {},
   "source": [
    "\n",
    "# üîç Hyperparameter Tuning in Neural Network\n",
    "\n",
    "This notebook explains what **hyperparameter tuning** is, how it works, why it's important, and demonstrates three common techniques:\n",
    "\n",
    "1. Grid Search\n",
    "2. Random Search\n",
    "3. Bayesian Optimization\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f916be",
   "metadata": {},
   "source": [
    "\n",
    "## üí° What is Hyperparameter Tuning?\n",
    "\n",
    "**Hyperparameters** are parameters that are set **before training** and are not learned from the data. Examples include:\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Number of hidden layers or neurons\n",
    "- Regularization strength\n",
    "\n",
    "**Hyperparameter tuning** is the process of finding the best combination of these values to **optimize model performance**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed432bb8",
   "metadata": {},
   "source": [
    "\n",
    "## üåü Why is Hyperparameter Tuning Important?\n",
    "\n",
    "Choosing the right hyperparameters can:\n",
    "- Increase accuracy\n",
    "- Reduce training time\n",
    "- Improve generalization (prevent overfitting or underfitting)\n",
    "\n",
    "Manual tuning is time-consuming, so we use automated strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b93482",
   "metadata": {},
   "source": [
    "\n",
    "## üß™ Grid Search\n",
    "\n",
    "**Grid Search** exhaustively tries every combination of hyperparameters from a predefined grid.\n",
    "\n",
    "### üîÅ How It Works:\n",
    "- Define a set of values for each hyperparameter.\n",
    "- Try **every possible combination** of these values.\n",
    "- Evaluate each using cross-validation or a validation set.\n",
    "\n",
    "üìå **Limitation**: Computationally expensive as it grows exponentially with the number of parameters.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7231f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50)}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       991\n",
      "           1       0.98      0.99      0.99      1064\n",
      "           2       0.97      0.98      0.98       990\n",
      "           3       0.98      0.96      0.97      1030\n",
      "           4       0.98      0.97      0.97       983\n",
      "           5       0.96      0.96      0.96       915\n",
      "           6       0.96      0.99      0.98       967\n",
      "           7       0.99      0.98      0.98      1090\n",
      "           8       0.97      0.96      0.97      1009\n",
      "           9       0.96      0.97      0.96       961\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\tf_2.2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Flatten the images for dense input\n",
    "x_train = x_train.reshape((-1, 28 * 28))\n",
    "x_test = x_test.reshape((-1, 28 * 28))\n",
    "\n",
    "# Split validation set from training data\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "\n",
    "# MLP and hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=20, random_state=42)\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "y_pred = grid_search.predict(x_val)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a569db",
   "metadata": {},
   "source": [
    "## üìò Understanding Parameters of GridSearchCV\n",
    "\n",
    "| Parameter                   | Description                                                                                                                               |\n",
    "| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`estimator=mlp`**         | The machine learning model to be optimized. In this case, `mlp` is an instance of `MLPClassifier`.                                        |\n",
    "| **`param_grid=param_grid`** | A dictionary specifying the grid of hyperparameters to search. Each key is a parameter name, and each value is a list of settings to try. |\n",
    "| **`cv=3`**                  | Number of cross-validation folds. The dataset is split into 3 parts for training/validation.                                              |\n",
    "| **`verbose=2`**             | Controls the level of verbosity. `2` prints progress messages after each combination is evaluated.                                        |\n",
    "| **`n_jobs=-1`**             | Number of jobs to run in parallel. `-1` uses all available processors for faster computation.                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb14cdb",
   "metadata": {},
   "source": [
    "\n",
    "## üé≤ Random Search\n",
    "\n",
    "**Random Search** samples random combinations of hyperparameters from a predefined distribution.\n",
    "\n",
    "### üîÅ How It Works:\n",
    "- Define a distribution or list of possible values.\n",
    "- Randomly select a fixed number of combinations.\n",
    "- Evaluate those combinations.\n",
    "\n",
    "üìå **Advantage**: Much faster than grid search and often finds a good result early.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5218cec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       991\n",
      "           1       0.98      0.99      0.99      1064\n",
      "           2       0.98      0.98      0.98       990\n",
      "           3       0.97      0.97      0.97      1030\n",
      "           4       0.98      0.98      0.98       983\n",
      "           5       0.98      0.95      0.96       915\n",
      "           6       0.98      0.99      0.98       967\n",
      "           7       0.98      0.98      0.98      1090\n",
      "           8       0.97      0.98      0.97      1009\n",
      "           9       0.97      0.96      0.97       961\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\tf_2.2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Define search space\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=20, random_state=42)\n",
    "random_search = RandomizedSearchCV(mlp, param_distributions=param_dist, n_iter=10, cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "y_pred = random_search.predict(x_val)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93018526",
   "metadata": {},
   "source": [
    "## üß© Parameters of `RandomizedSearchCV`\n",
    "\n",
    "| Parameter                 | Description                                                                                                                |\n",
    "| ------------------------- | -------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`estimator=mlp`**       | The model to be tuned. In this case, it's an instance of `MLPClassifier`.                                                  |\n",
    "| **`param_distributions`** | A dictionary or distribution object that defines the **range of hyperparameters** to sample from.                          |\n",
    "| **`n_iter=10`**           | The number of different combinations to sample and try. This is **not exhaustive**‚Äîonly 10 random combinations are tested. |\n",
    "| **`cv=3`**                | Number of folds for **cross-validation**. The model is evaluated on 3 different train/validation splits.                   |\n",
    "| **`verbose=2`**           | Controls the level of output verbosity. `2` prints one line per iteration.                                                 |\n",
    "| **`n_jobs=-1`**           | Number of jobs to run in parallel. `-1` means use **all available CPU cores**.                                             |\n",
    "| **`random_state=42`**     | Sets a **random seed** for reproducibility of the sampling and results.                                                    |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
