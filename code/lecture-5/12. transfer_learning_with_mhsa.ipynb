{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc049cb3",
   "metadata": {},
   "source": [
    "# Image Classification with Transfer Learning and Multi-Head Self-Attention\n",
    "\n",
    "In this notebook, we:\n",
    "- Explain what multi-head attention is\n",
    "- Understand its math and implementation\n",
    "- Build a CNN+Transformer hybrid model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc13ba7",
   "metadata": {},
   "source": [
    "## ü§Ø What is Multi-Head Attention?\n",
    "Multi-head attention extends self-attention by using multiple attention heads. Each head can learn different aspects of the data.\n",
    "\n",
    "This allows the model to capture various relationships in different subspaces of the input representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51fd38",
   "metadata": {},
   "source": [
    "## üí° Why Use Multi-Head Attention?\n",
    "Instead of learning a single attention function, multi-head attention projects the input into multiple lower-dimensional subspaces, learns attention separately, and then concatenates the outputs.\n",
    "\n",
    "This:\n",
    "- Improves representation power\n",
    "- Helps capture richer feature dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98c79d",
   "metadata": {},
   "source": [
    "## üßÆ Multi-Head Attention Math\n",
    "Given input $X \\in \\mathbb{R}^{T \\times D}$:\n",
    "1. Project to queries, keys, values for each head:\n",
    "   - $Q_i = XW^Q_i$, $K_i = XW^K_i$, $V_i = XW^V_i$ where $i=1,...,h$\n",
    "2. Compute attention per head:\n",
    "   - $A_i = \\text{softmax}(\\frac{Q_i K_i^T}{\\sqrt{d}}) V_i$\n",
    "3. Concatenate and project:\n",
    "   - $\\text{Concat}(A_1, ..., A_h) W^O$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.proj_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # [B, T, D] -> [B, h, T, d]\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.proj_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        Q = self.query_dense(inputs)\n",
    "        K = self.key_dense(inputs)\n",
    "        V = self.value_dense(inputs)\n",
    "\n",
    "        Q = self.split_heads(Q, batch_size)\n",
    "        K = self.split_heads(K, batch_size)\n",
    "        V = self.split_heads(V, batch_size)\n",
    "\n",
    "        score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(self.proj_dim, tf.float32))\n",
    "        weights = tf.nn.softmax(score / scale, axis=-1)\n",
    "\n",
    "        attention = tf.matmul(weights, V)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "        return self.combine_heads(concat_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa8179",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Build the Model with MobileNetV2 + Multi-Head Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_mhsa(num_classes=2):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "    x = base_model(x)                             # [B, 7, 7, 1280]\n",
    "    x = layers.Reshape((49, 1280))(x)             # [B, 49, 1280]\n",
    "\n",
    "    x = MultiHeadSelfAttention(embed_dim=1280, num_heads=8)(x)  # [B, 49, 1280]\n",
    "    x = layers.GlobalAveragePooling1D()(x)        # [B, 1280]\n",
    "    x = layers.Dense(256, activation='relu')(x)   # [B, 256]\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_model_with_mhsa(num_classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bddc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import os\n",
    "\n",
    "# Download the dataset from Microsoft (hosted by TensorFlow)\n",
    "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url, extract=True)\n",
    "\n",
    "# Get dataset path\n",
    "dataset_dir = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'validation')\n",
    "\n",
    "# Load data into TensorFlow datasets\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "val_dataset = image_dataset_from_directory(val_dir,\n",
    "                                           shuffle=True,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# Prefetch for performance\n",
    "train_dataset = train_dataset.prefetch(buffer_size=32)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=5, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d55233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
